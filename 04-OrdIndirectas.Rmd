##Ordenación indirecta o no constreñida

Las diferentes técnicas de ordenación, a excepción de los NMDS, se basan en la extracción de eigenvectors asociados con la matriz de datos. Los diferentes métodos de ordenación se pueden clasificar según la distancia preservada entre sitios y el tipo de variables que se usan.

Los métodos de  ordenación como lo habíamos comentado intentan obtener información sobre la heterogeneidad que tienen los datos. En términos sencillos la ordenación genera una nube de puntos basado en todas las variables (especies) que tiene nuestra comunidad, tendríamos un espacio multidimensional. Normalmente, esa nube de puntos será más alargada en ciertas direcciones y más aplanada en otras direcciones. La dirección donde la nube de puntos es más aplanada se corresponde con la dirección de mayor variabilidad de nuestros datos, donde el gradiente es más claro. Este es el primer eje de ordenación que se deberá extraer. A partir de aquí se buscarán otras direcciones que vayan en forma decreciente la cantidad de variación explicada (menos alargada). Cada eje extraído es ortogonal a los otros ejes, eso quiere decir que son linearmente independientes y no correlacionados.

Cuando en los datos hay estructuras claras (gradientes o grupos) y el método ha sido eficiente para extraerlas, entonces los primeros ejes contienen la mayor parte de la información útil, es decir, han extraído la mayor parte de la varianza de los datos. En ese caso, las distancias entre sitios en la proyección en un espacio reducido (con mayor frecuencia bidimensional) son relativamente similares a las distancias entre objetos en el espacio multidimensional.

Como lo comentamos anteriormente el decidir que ordenación usar depende del tipo de respuesta que tienen los datos y de la distancia que se utilizará. De esta forma, si los datos muestran una respuesta lineal se puede usar un análisis de componentes principales (PCA), mientras que si es unimodal podemos ajustar un análisis de correspondiente (CA) o análisis de correspondencia sin tendencia (DCA) (Tabla \@ref(tab:ordenacion))

```{r ordenacion, echo=FALSE}
Ordenacion<- data.frame(`Medidas de Similitud` = c("Respuesta lineal", "Respuesta Unimodal", "Bray-Curtis"), `Tipo de Ordenación` = c("PCA", "CA/DCA", "PcoA/mMDS/nmMDS"))

knitr::kable(
  Ordenacion, booktabs = TRUE,
  caption = 'Relación entre el tipo de variable y el método de ordenación no constreñida a utilizar'
)
```

###Métodos de ordenación.

__*1. Principal Component Analysis (PCA)*__

Esta técnica de ordenación es sencilla de interpretar, las distancias entre las muestras son interpretadas directamente como distancias euclidianas. Este método de ordenación es ampliamente usado con datos ambientales, donde el valor de cero es informativo, aunque se puede usar en datos biológicos previo una transformación. El PCA al usar distancias euclidianas es fuertemente afectado por ceros, y detecta relaciones lineares de los datos.

Además de las limitantes de los dobles ceros, otro inconveniente que puede tener esta ordenación, es que la proyección de las distancias euclidias en un plano puede distorsionar algunas distancias en otros planos.

Los gráficos de dispersión de la ordenación PCA, los objetos (las comunidades) se representan como puntos y las variables se muestran como flechas.

Ahora vamos hacer un ejercicio rápido y ajustar un PCA a datos de arrestos en Estados Unidos. Estos datos que se encuentran en el paquete base de R contiene el porcentaje de asaltos (Assault), asesinatos (Murder) y secuestros (Rape) por cada 100,000 habitantes para cada uno de los 50 estados de USA (1973). Además, también incluye el porcentaje de la población de cada estado que vive en zonas rurales (UrbanPoP).

```{r}
library(vegan)
data("USArrests")
head(USArrests, 4)

#usaremos la función rda para ajustar un pca
pca.Arr <- rda(USArrests, scale = TRUE)

#el argumento scale = TRUE nos permite estandarizar los datos 
#los arrestos como vemos son mucho más altos que las otras variables

#Vemos el resultado del ajuste
pca.summ <- summary(pca.Arr)

#Eigenvalues
#para obtener los eignvalues le pedimos que del objeto que contiene el resumen del
#análisis (pca.summ) el elemento cont 
pca.summ$cont
```

Los _eigenvalores_ son medidas de la importancia (varianza) de los ejes. Pueden expresarse como proporciones explicadas, o proporciones de variación explicadas, dividiéndolas por la inercia total. En el caso del ejemplo vemos que el componente 1 (PC1) explica el 62% de la varianza de nuestros datos, y el segundo componente (PC2) el 24% en conjunto estos dos componentes explican el 86% de la variación de los datos.

```{r}
#puntuación de las especies 
pca.summ$species

```

La puntuación de las especies nos muestra cómo se asocia el primer componente a esa variable y el peso de esa variable. De esta forma, en el ejemplo, en el primer componente las variables Assault, Murder y Rape son aproximadamente iguales entre ellas y bastante superiores al asignado a UrbanPoP y tienen una asociación negativa. En el caso del componente dos UrbanPop tiene un peso más importante en ese eje y su relación es negativa. Cuando usamos _vegan_ para ajustar una ordenación las variables siempre serán mostradas como especies.

```{r}
#Sitios
#Usamos la función head para que se despliegue únicamente los 6 primeros sitios
head(pca.summ$sites)

```

Sitios se refiere al valor que recibe cada uno de los sitios (observaciones) en cada uno de los componentes, en un gráfico de doble entrada serían las coordenadas. 

Finalmente, cuando queremos mostrar nuestra ordenación en un biplot o gráfico de dispersión, la forma en que se muestran los resultados puede estar definidos de dos formas distintas. Scaling 1 es usado normalmente cuando nos interesa ver las diferencias entre los sitios. Mientras que scaling 2 es usado si lo que nos interesa es evaluar la relación entre las variables.  Veamos la diferencia en la representación gráfica.

```{r, warning=FALSE}
par(mfcol=c(1,2))

biplot(pca.Arr, scaling=1, main = "Scaling 1")
biplot(pca.Arr, scaling=2, main = "Scaling 2")

```

__*2. Principal Coordinates Análisis (PCoA)*__ 

PCoA, conocido también como escalado métrico multidimensional (MDS) es conceptualmente similar a PCA y análisis de correspondencia (CA) que preservan distancias Eudlicean y chi-cuadrado entre objetos, respectivamente, la diferencia con estos métodos de ordenación es que el PCoA puede preservar las distancias generadas a partir de cualquier medida de  similitud o disimilitud permitiendo un manejo más flexible de datos ecológicos complejos. PCA se usa comúnmente para similitudes y PCoA para diferencias.

Una ventaja importante es que el PCoA permite manejar matrices de disimilitud calculadas a partir de variables cuantitativas, semicuantitativas, cualitativas y mixtas. En este caso la elección de la medida de similitud o disimilitud es crítica y debe ser adecuada para los datos con los que se está trabajando. 

Aunque, este método presenta varias ventajas hay que recordad que el PCoA representa en el plano los componentes euclidianos de la matriz, incluso si la matriz contiene distancias no euclidianas. 

Usaremos el paquete __ape__ para implementar el PCoA y la función _pcoa_ que computa la ordenación, para esto necesitamos una matriz de distancias o similitudes como entrada, usaremos el paquete __cluster__ y la función _daisy_ para calcular la distancia de gower.

```{r}
#cargamos datos de ejemplo
library(vegan)
data("dune.env")

#calculamos la distancia de gower con datos mixtos
#variables numéricas y categóricas
library(cluster)
disGow <- daisy(dune.env, "gower")

#realizamos la ordenación y graficamos
library(ape)
pcoaDun <- pcoa(disGow)

#vemos los eigenvalores
head(pcoaDun$values)

#Estos nos muestran la importancia de cada variable para cada sitio

#Vemos los eigenvectores
head(pcoaDun$vectors)
#son los vectores que se usan para la ordenación 
```

Muy bien ahora podemos graficar los datos y ver como se organizan en el espacio.

```{r}
plot(pcoaDun$vectors[,1], pcoaDun$vectors[,2], type = "n", xlab = "PCoA1", ylab = "PCoA2",
 axes = TRUE, main = "PCoA dune.env data")

text(pcoaDun$vectors[,1], pcoaDun$vectors[,2], labels(disGow), 
 cex = 0.9, xpd = TRUE)
```


__*3. Correspondence Analysis (CA)*__

Implícitamente se generan distancias de Chi-cuadrado entre las muestras por lo que no es afectado por matrices con dobles ceros. Se basa en un modelo de respuesta unimodal de las especies a los gradientes ambientales subyacentes. Uno de los principales problemas de este análisis es que la ordenación genera un “Efecto arco” causado por la respuesta unimodal de la abundancia de especies a un gradiente ambiental.

Este análisis es implementado dentro del paquete __vegan__, para ajustar un CA usamos la función _cca_ 

```{r}
data(dune)

#ajustamos el ca
ca.dune <- cca(dune)

#extraemos los datos
caSum <- summary(ca.dune)

#Eigenvalores
caSum$cont
#el primer componente explica el 25% de la variación

#Ahora graficamos
par(mfcol=c(1,2))
plot(ca.dune, scaling = 1, main="CA scaling 1")
plot(ca.dune, scaling = 2, main="CA scaling 2")

```

__Recuerde:__ Al igual que en el PCA usamos _scaling 1_ cuando lo que nos interesa es evaluar la relación entre sitios, mientras que _scaling 2_ usamos cuando nos interesa evaluar la relación entre especies.


__*4. Detrended Correspondence Analysis (DCA, DECORANA)*__ 

Es una extensión del CA que corrige el efecto arco. Este método realiza una ordenación por segmentos y luego los alinea con el fin de evitar la curvatura. Muchos autores proponen que este tipo de análisis implica una excesiva manipulación de los datos (Pielou 1984).

Este análisis es implementado dentro del paquete __vegan__, para ajustar un CA usamos la función _dca_ 

```{r}
#ajustamos el dca
dca.dune <- decorana(dune)
dca.dune

#Ahora graficamos
par(mfcol=c(1,2))
plot(dca.dune)

```
__*5. Nonmetric Multidimensional Scaling (NMDS)*__

Una de las principales características de este método es que permite ajustar la ordenación con cualquier método de distancias. De esta forma se pueden usar distancias que sean biológicamente relevantes. Un problema de este método es que la ordenación de las muestras utiliza el orden relativo de las distancias entre muestras y no los valores absolutos de los coeficientes de similitud. Esto significa que si la muestra 1 es más parecida a la 2 que a la 3 entonces se localizará más cercana a la muestra 2 que a la 3, sin embargo, esa diferencias entre distancias no necesariamente tendrá la dimensión exacta. Por eso la representación gráfica del nMDS sufre menos distorsiones respecto a las distancias reales.


```{r, message=FALSE, cache.comments=FALSE,results='hide'}
nmds.dune <- metaMDS(dune,distance="bray", k=2, trymax=50)   
nmds.dune 
```

A diferencia de los otros métodos que hemos visto hasta aquí el NMDS, el stress es el que nos muestra que tan efectiva ha sido la ordenación. El valor de estrés (stress) nos indica la cantidad de varianza que  __NO__ se ajustó, mientras más bajo es el estrés mayor varianza explica. Una regla general, aunque discutida, es que las ordenaciones con estrés >0.05 proporciona una representación _excelente_ en las dimensiones reducidas, >0.1 es _muy bueno_, >0.2 es _bueno_ con valores de estrés >0.3 se dice que la ordenación proporciona una pobre representación de la variación de los datos. En nuestro ejemplo el estrés podría considerarse muy bueno.

```{r}
#graficamos la ordenación

plot(nmds.dune, main="NMDS de los datos de Dune")
```

###Graficar los resultados

Como hemos visto existen diferentes formas de graficar los resultados de la ordenación. A continuación mostramos una forma de personalización del gráfico de ordenación que se aplica a la mayor parte de ordenaciones.

```{r plotnmds, fig.align='center', fig.width=4.5, fig.height=4.5, fig.cap= "Representación gráfica del NMDS"}
plot(nmds.dune, type="n")  # para dibujar un plot vacío
points(nmds.dune, display="sites", cex=0.8, pch=21, col="black", bg="yellow")  
text(nmds.dune, display= "spec", cex=0.5, col="blue") 

```
Podemos ver en la figura \@ref(fig:plotnmds) que ciertas especies están asociadas con ciertas localidades esto nos podría servir para explorar los datos.


###Interpretación ambiental

Como lo mencionamos previamente las ordenaciones indirectas no sirven para testar hipótesis, este método nos permite organizar nuestras variables en un espacio dimensional más reducido.  Sin embargo, podríamos usar estos ejes y relacionarlos con variables ambientales. Vamos a usar el paquete vegan para ajustar un modelo que permita evaluar el efecto de las variables ambientales a la ordenación.


```{r}
data(varechem)
data(varespec)
vare.mds <- metaMDS(varespec, trace = FALSE)
ef <- envfit(vare.mds, varechem, permu = 999)
ef
```

Ahora podemos ver las variables que son significativas para explicar la ordenación de los datos.

```{r}
plot(vare.mds, display = "sites")
plot(ef, p.max = 0.05)

```

Con variables categóricas podríamos hacer el mismo procedimiento pero tener una gráfica de salida un poco diferente.

```{r}
ef <- envfit(ca.dune, dune.env, permutations = 999)
ef

plot(ca.dune, display = "sites", type = "p")
with(dune.env, ordiellipse(ca.dune, Management, kind = "se", conf = 0.95, label= TRUE))
```

###Ejercicio

Los datos que se presentan [aquí]("https://github.com/Ciespinosa/AnalisisMultivariante/blob/gh-pages/TraitsVege.csv") corresponden a rasgos asociados a procesos de dispersión de semillas, incluyendo los potenciales grupos de dispersores. Colectamos información de 10 rasgos de frutos y semillas de 71 especies leñosas. Se registraron seis rasgos de frutos; tipo, color, peso, largo, ancho y número de semillas. Para semillas se registraron tres rasgos; peso, longitud y ancho. Adicionalmente se asignó un síndrome de dispersión a cada especie.

Los rasgos de frutos y semillas colectados en este trabajo, han sido asociados con la habilidad de las plantas para lidiar con el estrés. Muller-Landau (2010) sugiere que las especies con semillas pequeñas tienen una ventaja en fertilidad y dispersión, por producir más semillas y facilitar su desplazamiento a grandes distancias. Por otro lado, las semillas grandes tienen la ventaja de la tolerancia al estrés, porque estas proveen energía y material para el crecimiento de las plántulas. Una mayor contribución de nutrientes en semillas grandes facilita la sobrevivencia bajo ambientes más estresantes, ya sea por sombra, humedad, herbivoría o perturbaciones.

En este contexto, esperamos que los ambientes menos estresantes estén dominados por especies con semillas pequeñas, pero un amplio rango de tamaños de semillas. En ambientes de mayor estrés, se espera encontrar un subconjunto de especies con semillas grandes y baja capacidad de dispersión.

Para analizar el impacto del disturbio sobre la estructura de la comunidad en términos de rasgos funcionales usaremos tres variables que han mostrado ser un subrogado de perturbaciones antrópicas; (1) distancia al centro poblado más cercano, (2) peso de excretas de ganado, (3) número de árboles con DBH > 20 cm, donde un bajo número de árboles grandes implica una alta perturbación. Puede obtener los datos de [aquí]("https://github.com/Ciespinosa/AnalisisMultivariante/blob/gh-pages/Parcelas.csv")

Vamos a analizar por separado los rasgos cualitativos y los cuantitativos.

Para analizar los efectos de la perturbación sobre los rasgos cualitativos de los frutos vamos a ajustar un PCA para cada rasgo; tipo de fruto, síndrome de dispersión y color del fruto. Utilizaremos la matriz de datos morfológicos cualitativos.
Realizamos un modelo lineal usando el primer eje del PCA como variable de respuesta y cada una de las tres variables de perturbación como variables explicativas. Usaremos la función “rda” del paquete “vegan” para ajustar el PCA, y la función “lm” del paquete “stats” para el modelo lineal.
